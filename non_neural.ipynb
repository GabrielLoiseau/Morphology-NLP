{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Neural Approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "language_path_train = \"./task0-data/DEVELOPMENT-LANGUAGES/niger-congo/swa.trn\"\n",
    "\n",
    "f = open(language_path_train,encoding=\"utf-8\")\n",
    "\n",
    "lemmas = []\n",
    "form = []\n",
    "morph = []\n",
    "\n",
    "for lines in f.readlines():\n",
    "    a, b, c = lines.split(\"\\t\")\n",
    "    lemmas.append(a)\n",
    "    form.append(b)\n",
    "    morph.append(c.split(\";\")[:-2])\n",
    "\n",
    "def distance(str1, str2):\n",
    "    \"\"\"Simple Levenshtein implementation for eval.\"\"\"\n",
    "    m = np.zeros([len(str2)+1, len(str1)+1])\n",
    "    for x in range(1, len(str2) + 1):\n",
    "        m[x][0] = m[x-1][0] + 1\n",
    "    for y in range(1, len(str1) + 1):\n",
    "        m[0][y] = m[0][y-1] + 1\n",
    "    for x in range(1, len(str2) + 1):\n",
    "        for y in range(1, len(str1) + 1):\n",
    "            if str1[y-1] == str2[x-1]:\n",
    "                dg = 0\n",
    "            else:\n",
    "                dg = 1\n",
    "            m[x][y] = min(m[x-1][y] + 1, m[x][y-1] + 1, m[x-1][y-1] + dg)\n",
    "    return int(m[len(str2)][len(str1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def make_alphabet(dictionnary):\n",
    "    \"\"\"From a list of words, create an empirical dictionnary of words\"\"\"\n",
    "    scores = {}\n",
    "    for word in dictionnary:\n",
    "        for letter in word:\n",
    "            if letter in scores.keys():\n",
    "                scores[letter] += 1\n",
    "            elif letter not in string.punctuation:\n",
    "                scores[letter] = 1\n",
    "    for v in scores.keys():\n",
    "        scores[v] /= len(scores)\n",
    "    \n",
    "    return scores\n",
    "           \n",
    "            \n",
    "\n",
    "def word_score(word,alphabet_scores):\n",
    "    score = 0\n",
    "    for letter in word:\n",
    "        try:\n",
    "            score += alphabet_scores[letter]\n",
    "        except:\n",
    "            continue\n",
    "    return score\n",
    "\n",
    "\n",
    "# Function to find the longest common substring\n",
    "def LCS(X, Y):\n",
    "    m = len(X)\n",
    "    n = len(Y)\n",
    "    maxLength = 0 \n",
    "    endingIndex = m\n",
    "    lookup = [[0 for x in range(n + 1)] for y in range(m + 1)]\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if X[i - 1] == Y[j - 1]:\n",
    "                lookup[i][j] = lookup[i - 1][j - 1] + 1\n",
    "                if lookup[i][j] > maxLength:\n",
    "                    maxLength = lookup[i][j]\n",
    "                    endingIndex = i\n",
    "    return X[endingIndex - maxLength: endingIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list containing evey morph attribute but our language\n",
    "transformed = []\n",
    "radical = []\n",
    "lemmas, form, morph = [lemmas, form, morph]\n",
    "alphabet = make_alphabet(form)\n",
    "for i in range(len(lemmas)):\n",
    "    sub = LCS(lemmas[i],form[i])\n",
    "    transformed.append(form[i].replace(sub,\"[word]\"))\n",
    "    radical.append(lemmas[i].replace(sub,\"[word]\"))\n",
    "\n",
    "morph_list = set([b for array in morph for b in array]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COND', 'DEF', 'FIN', 'HAB', 'IND', 'INDF', 'PL', 'PRF', 'SG', 'V'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3374, 3374, 3374)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transformed), len(form), len(morph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buildling dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e216c50aa54046f2ae507aea656f0fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3374.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# df = pd.DataFrame(columns=list(morph_list)+[\"form\"])\n",
    "# complete matrix\n",
    "M = []\n",
    "\n",
    "# Every index in size(all_words)\n",
    "for i in tqdm(range(len(transformed))):\n",
    "    # new array\n",
    "    morph_attributes = []\n",
    "    # morph_choice = 'V' in morph_properies = {'V', 'I', '1', '2', 'J', 'O', 'T', 'G', '3', 'D', 'L', 'S', 'N', 'C', 'A', 'M', 'P'}\n",
    "    for morph_choice in morph_list:\n",
    "        # if 'V' in [N,1,J]\n",
    "        if morph_choice in list(morph[i]):\n",
    "            #print(f\"{morph_choice} in {morph_properies}\")\n",
    "            morph_attributes.append(1)\n",
    "        else:\n",
    "            #print(f\"{morph_choice} not in {morph_properies}\")\n",
    "            morph_attributes.append(0)\n",
    "           \n",
    "                \n",
    "    #M.append(morph_attributes + [transformed[i]])\n",
    "    M.append(morph_attributes + [lemmas[i]] + [radical[i]] + [form[i]] + [transformed[i]])\n",
    "\n",
    "M_n = np.array(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study over duplicates of morphological attributes\n",
    "mask = (M_n[:,3] == '1')\n",
    "M_n[mask,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'Hallo', 'hallo']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import difflib\n",
    "words = ['hello', 'Hallo', 'hi', 'house', 'key', 'screen', 'hallo', 'question', 'format']\n",
    "difflib.get_close_matches('Hello', words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f8780ecdfe4ed6b46a0a1943937a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=910.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "language_path_test = \"./task0-data/DEVELOPMENT-LANGUAGES/niger-congo/swa.tst\"\n",
    "\n",
    "f = open(language_path_test,encoding=\"utf-8\")\n",
    "\n",
    "lemmas_test = []\n",
    "morph_test = []\n",
    "\n",
    "for lines in f.readlines():\n",
    "    a, b = lines.split(\"\\t\")\n",
    "    lemmas_test.append(a)\n",
    "    morph_test.append(b.split(\";\")[:-2])\n",
    "\n",
    "\n",
    "df = pd.DataFrame(M_n,columns=list(morph_list)+[\"lemma\"]+[\"radical\"]+[\"form\"]+[\"prefix_suffix\"])\n",
    "\n",
    "#test_set = df.sample(int(len(df)*0.05))\n",
    "\n",
    "res = []\n",
    "\n",
    "for i in tqdm(range(len(lemmas_test))):\n",
    "    copy = df\n",
    "    guess = lemmas_test[i]\n",
    "    guess_morph = morph_test[i]\n",
    "\n",
    "    for v in guess_morph:\n",
    "        copy = copy[copy[v] == '1']\n",
    "\n",
    "    for a in morph_list:\n",
    "        if a not in guess_morph:\n",
    "            copy = copy[copy[a] == '0']\n",
    "\n",
    "    best_index = -1\n",
    "    best_word = ''\n",
    "    for index, row in copy.iterrows():\n",
    "        if distance(guess, row['lemma']) < distance(guess, best_word):\n",
    "            best_index = index\n",
    "            best_word = row['lemma']\n",
    "    #print(\"Guess\",guess,\"Best_word\",best_word,\"Best_index\",lemmas[best_index])\n",
    "    #print(copy.loc[best_index])\n",
    "    #print(transformed[best_index].replace('[word]',guess.replace(radical[best_index].replace('[word]',''),'')),\"->\",form[i])\n",
    "    #print(lemmas[i])\n",
    "    res.append(transformed[best_index].replace('[word]',guess.replace(radical[best_index].replace('[word]',''),'')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Mean Distance Average lemma length\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.42, 2.3, 9.057142857142857)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_path_gold = \"./task0-data/GOLD-TEST/swa.tst\"\n",
    "\n",
    "f = open(language_path_gold,encoding=\"utf-8\")\n",
    "\n",
    "lemmas_true = []\n",
    "form_true = []\n",
    "morph_true = []\n",
    "\n",
    "for lines in f.readlines():\n",
    "    a, b, c = lines.split(\"\\t\")\n",
    "    lemmas_true.append(a)\n",
    "    form_true.append(b)\n",
    "    morph_true.append(c.split(\";\")[:-2])\n",
    "\n",
    "def eval_form(gold, guess):\n",
    "    \"\"\" compute average accuracy and edit distance for task 0 \"\"\"\n",
    "    correct, dist, total = 0., 0., 0.\n",
    "    mean_lean = 0\n",
    "    for i in range(len(gold)):\n",
    "        mean_lean += len(gold[i])\n",
    "        if gold[i] == guess[i]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            dist += distance(gold[i],guess[i])\n",
    "        total += 1\n",
    "    mean_lean /= len(gold)\n",
    "    return (round(correct/total*100, 2), round(dist/total, 2), mean_lean)\n",
    "\n",
    "print(\"Accuracy\",\"Mean Distance\", \"Average lemma length\")\n",
    "eval_form(form_true, res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Misc. testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur bakwaˀan -> rukwaˀan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#WIP : 06/02\n",
    "guess =  'proidie'\n",
    "guess_morph = ['V', 'IND', 'PL', '1']\n",
    "df = pd.DataFrame(M_n,columns=list(morph_list)+[\"lemma\"]+[\"radical\"]+[\"form\"]+[\"prefix_suffix\"])\n",
    "\n",
    "#test_set = df.sample(int(len(df)*0.05))\n",
    "test_set = df.sample(1)\n",
    "df = df.drop(test_set.index)\n",
    "\n",
    "correct = 0\n",
    "for i, _ in test_set.iterrows():\n",
    "    copy = df\n",
    "    guess = lemmas[i]\n",
    "    guess_morph = morph[i]\n",
    "\n",
    "    for v in guess_morph:\n",
    "        copy = copy[copy[v] == '1']\n",
    "\n",
    "    for a in morph_list:\n",
    "        if a not in guess_morph:\n",
    "            copy = copy[copy[a] == '0']\n",
    "\n",
    "    best_index = -1\n",
    "    best_word = ''\n",
    "    for index, row in copy.iterrows():\n",
    "        if distance(guess, row['lemma']) < distance(guess, best_word):\n",
    "            best_index = index\n",
    "            best_word = row['lemma']\n",
    "    #print(\"Guess\",guess,\"Best_word\",best_word,\"Best_index\",lemmas[best_index])\n",
    "    #print(copy.loc[best_index])\n",
    "    #print(transformed[best_index].replace('[word]',guess.replace(radical[best_index].replace('[word]',''),'')),\"->\",form[i])\n",
    "    #print(lemmas[i])\n",
    "    if transformed[best_index].replace('[word]',guess.replace(radical[best_index].replace('[word]',''),'')) == form[i]:\n",
    "        correct += 1\n",
    "    else:\n",
    "        print(\"Erreur\",transformed[best_index].replace('[word]',guess.replace(radical[best_index].replace('[word]',''),'')),\"->\",form[i])\n",
    "        pass\n",
    "\n",
    "correct / float(len(test_set)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nitakamilisha',\n",
       " 'nilifagia',\n",
       " 'wanaponda',\n",
       " 'tungalimwita',\n",
       " 'ameondoa',\n",
       " 'tuhuchafya',\n",
       " 'ninaficha',\n",
       " 'ningeomba',\n",
       " 'tumebofya',\n",
       " 'mlifuata']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "form_true[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['utakamilisha',\n",
       " 'nitafagia',\n",
       " 'mnaponda',\n",
       " 'wangalimwita',\n",
       " 'umeondoa',\n",
       " 'wahuchafya',\n",
       " 'unaficha',\n",
       " 'ningaliomba',\n",
       " 'wamebofya',\n",
       " 'walifuata']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V</th>\n",
       "      <th>SG</th>\n",
       "      <th>PRF</th>\n",
       "      <th>PL</th>\n",
       "      <th>HAB</th>\n",
       "      <th>DEF</th>\n",
       "      <th>FIN</th>\n",
       "      <th>INDF</th>\n",
       "      <th>COND</th>\n",
       "      <th>IND</th>\n",
       "      <th>lemma</th>\n",
       "      <th>radical</th>\n",
       "      <th>form</th>\n",
       "      <th>prefix_suffix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>tengeneza</td>\n",
       "      <td>[word]</td>\n",
       "      <td>nitatengeneza</td>\n",
       "      <td>nita[word]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>choma</td>\n",
       "      <td>[word]</td>\n",
       "      <td>ulichoma</td>\n",
       "      <td>uli[word]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>pika</td>\n",
       "      <td>[word]</td>\n",
       "      <td>atapika</td>\n",
       "      <td>ata[word]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>tafuta</td>\n",
       "      <td>[word]</td>\n",
       "      <td>nilitafuta</td>\n",
       "      <td>nili[word]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>funga</td>\n",
       "      <td>[word]</td>\n",
       "      <td>utafunga</td>\n",
       "      <td>uta[word]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3343</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>panda</td>\n",
       "      <td>[word]</td>\n",
       "      <td>utapanda</td>\n",
       "      <td>uta[word]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3347</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>kopa</td>\n",
       "      <td>[word]</td>\n",
       "      <td>nitakopa</td>\n",
       "      <td>nita[word]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3353</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>lia</td>\n",
       "      <td>[word]</td>\n",
       "      <td>nitalia</td>\n",
       "      <td>nita[word]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3359</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ruka</td>\n",
       "      <td>[word]</td>\n",
       "      <td>utaruka</td>\n",
       "      <td>uta[word]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3366</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>lamba</td>\n",
       "      <td>[word]</td>\n",
       "      <td>atalamba</td>\n",
       "      <td>ata[word]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>422 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      V SG PRF PL HAB DEF FIN INDF COND IND      lemma radical           form  \\\n",
       "3     1  1   0  0   0   0   1    0    0   1  tengeneza  [word]  nitatengeneza   \n",
       "11    1  1   0  0   0   0   1    0    0   1      choma  [word]       ulichoma   \n",
       "38    1  1   0  0   0   0   1    0    0   1       pika  [word]        atapika   \n",
       "48    1  1   0  0   0   0   1    0    0   1     tafuta  [word]     nilitafuta   \n",
       "54    1  1   0  0   0   0   1    0    0   1      funga  [word]       utafunga   \n",
       "...  .. ..  .. ..  ..  ..  ..  ...  ...  ..        ...     ...            ...   \n",
       "3343  1  1   0  0   0   0   1    0    0   1      panda  [word]       utapanda   \n",
       "3347  1  1   0  0   0   0   1    0    0   1       kopa  [word]       nitakopa   \n",
       "3353  1  1   0  0   0   0   1    0    0   1        lia  [word]        nitalia   \n",
       "3359  1  1   0  0   0   0   1    0    0   1       ruka  [word]        utaruka   \n",
       "3366  1  1   0  0   0   0   1    0    0   1      lamba  [word]       atalamba   \n",
       "\n",
       "     prefix_suffix  \n",
       "3       nita[word]  \n",
       "11       uli[word]  \n",
       "38       ata[word]  \n",
       "48      nili[word]  \n",
       "54       uta[word]  \n",
       "...            ...  \n",
       "3343     uta[word]  \n",
       "3347    nita[word]  \n",
       "3353    nita[word]  \n",
       "3359     uta[word]  \n",
       "3366     ata[word]  \n",
       "\n",
       "[422 rows x 14 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_guess = lemmas_test[0]\n",
    "to_guess_morph = morph_test[0]\n",
    "\n",
    "df = pd.DataFrame(M_n,columns=list(morph_list)+[\"lemma\"]+[\"radical\"]+[\"form\"]+[\"prefix_suffix\"])\n",
    "copy = df\n",
    "\n",
    "for v in to_guess_morph:\n",
    "    copy = copy[copy[v] == '1']\n",
    "\n",
    "for a in morph_list:\n",
    "    if a not in to_guess_morph:\n",
    "        copy = copy[copy[a] == '0']\n",
    "\n",
    "copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^.+tiä$\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def to_regex(word):\n",
    "    return \"^\" + word.replace(\"[word]\",\".+\") + \"$\"\n",
    "\n",
    "bool(re.match(r\"^.+tua$\",'unahtua'))\n",
    "print(to_regex('[word]tiä'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original word : kamilisha\n",
      "Closest word found : [word]\n",
      "Result :\n",
      "ningalisema\n",
      "Truth :\n",
      "nitakamilisha\n"
     ]
    }
   ],
   "source": [
    "best_index = -1\n",
    "best_word = ''\n",
    "\"\"\"\n",
    "for index, row in copy.iterrows():\n",
    "    if distance(guess, row['lemma']) < distance(guess, best_word):\n",
    "        best_index = index\n",
    "        best_word = row['lemma']\"\"\"\n",
    "\n",
    "\n",
    "for index, rad in enumerate(df[\"radical\"].values.tolist()):\n",
    "    if bool(re.match(to_regex(rad),to_guess)) and len(rad) >= len(best_match):\n",
    "        #print(transformed[best_match_index], best_match)\n",
    "        best_index, best_word = index, rad\n",
    "\n",
    "print(transformed[best_match_index].replace('[word]',to_guess.replace(radical[best_match_index].replace('[word]',''),'')))\n",
    "\n",
    "print(\"Original word :\",to_guess)\n",
    "print(\"Closest word found :\",best_word)\n",
    "print(\"Result :\")\n",
    "print(transformed[best_index].replace('[word]',guess.replace(radical[best_index].replace('[word]',''),'')))\n",
    "print(\"Truth :\")\n",
    "print(form_true[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IND</th>\n",
       "      <th>INDF</th>\n",
       "      <th>DEF</th>\n",
       "      <th>PL</th>\n",
       "      <th>PRF</th>\n",
       "      <th>HAB</th>\n",
       "      <th>COND</th>\n",
       "      <th>V</th>\n",
       "      <th>SG</th>\n",
       "      <th>FIN</th>\n",
       "      <th>lemma</th>\n",
       "      <th>radical</th>\n",
       "      <th>form</th>\n",
       "      <th>prefix_suffix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>anguka</td>\n",
       "      <td>[word]</td>\n",
       "      <td>ulianguka</td>\n",
       "      <td>uli[word]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>anguka</td>\n",
       "      <td>[word]</td>\n",
       "      <td>wangeanguka</td>\n",
       "      <td>wange[word]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>anguka</td>\n",
       "      <td>[word]</td>\n",
       "      <td>tumeanguka</td>\n",
       "      <td>tume[word]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>anguka</td>\n",
       "      <td>[word]</td>\n",
       "      <td>ahuanguka</td>\n",
       "      <td>ahu[word]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>anguka</td>\n",
       "      <td>[word]</td>\n",
       "      <td>tulianguka</td>\n",
       "      <td>tuli[word]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>anguka</td>\n",
       "      <td>[word]</td>\n",
       "      <td>kuanguka</td>\n",
       "      <td>ku[word]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    IND INDF DEF PL PRF HAB COND  V SG FIN   lemma radical         form  \\\n",
       "29    1    0   0  0   0   0    0  1  1   1  anguka  [word]    ulianguka   \n",
       "172   0    0   0  1   0   0    1  1  0   1  anguka  [word]  wangeanguka   \n",
       "246   1    0   0  1   1   0    0  1  0   1  anguka  [word]   tumeanguka   \n",
       "262   1    0   0  0   0   1    0  1  1   1  anguka  [word]    ahuanguka   \n",
       "315   1    0   0  1   0   0    0  1  0   1  anguka  [word]   tulianguka   \n",
       "336   0    0   0  0   0   0    0  0  0   0  anguka  [word]     kuanguka   \n",
       "\n",
       "    prefix_suffix  \n",
       "29      uli[word]  \n",
       "172   wange[word]  \n",
       "246    tume[word]  \n",
       "262     ahu[word]  \n",
       "315    tuli[word]  \n",
       "336      ku[word]  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(M_n,columns=list(morph_list)+[\"lemma\"]+[\"radical\"]+[\"form\"]+[\"prefix_suffix\"])\n",
    "d2 = df[(df['lemma']==\"anguka\")]\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IND</th>\n",
       "      <th>INDF</th>\n",
       "      <th>DEF</th>\n",
       "      <th>PL</th>\n",
       "      <th>PRF</th>\n",
       "      <th>HAB</th>\n",
       "      <th>COND</th>\n",
       "      <th>V</th>\n",
       "      <th>SG</th>\n",
       "      <th>FIN</th>\n",
       "      <th>lemma</th>\n",
       "      <th>radical</th>\n",
       "      <th>form</th>\n",
       "      <th>prefix_suffix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [IND, INDF, DEF, PL, PRF, HAB, COND, V, SG, FIN, lemma, radical, form, prefix_suffix]\n",
       "Index: []"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = df[(df['form']==\"nihuandika\")]\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original word : kamilisha\n",
      "Closest word found : [word]\n",
      "Result :\n",
      "atasema\n",
      "Truth :\n",
      "nitakamilisha\n"
     ]
    }
   ],
   "source": [
    "to_guess = lemmas_test[0]\n",
    "to_guess_morph = morph_test[0]\n",
    "\n",
    "df = pd.DataFrame(M_n,columns=list(morph_list)+[\"lemma\"]+[\"radical\"]+[\"form\"]+[\"prefix_suffix\"])\n",
    "copy = df\n",
    "\n",
    "for v in to_guess_morph:\n",
    "    copy = copy[copy[v] == '1']\n",
    "\n",
    "for a in morph_list:\n",
    "    if a not in to_guess_morph:\n",
    "        copy = copy[copy[a] == '0']\n",
    "\n",
    "best_match_index = -1\n",
    "best_match = ''\n",
    "for index, rad in enumerate(copy[\"radical\"].values.tolist()):\n",
    "    if bool(re.match(to_regex(rad),to_guess)) and len(rad) >= len(best_match):\n",
    "        #print(transformed[best_match_index], best_match)\n",
    "        best_match_index, best_match = index, rad\n",
    "\n",
    "print(\"Original word :\",to_guess)\n",
    "print(\"Closest word found :\",best_match)\n",
    "print(\"Result :\")\n",
    "print(transformed[best_match_index].replace('[word]',guess.replace(radical[best_match_index].replace('[word]',''),'')))\n",
    "print(\"Truth :\")\n",
    "print(form_true[0])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4b3e1fd528db97e575ee821c2b156c07c8c260dd3342572e970d2971df44776e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
